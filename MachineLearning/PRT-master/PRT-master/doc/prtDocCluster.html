
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>PRT Clustering Objects</title><meta name="generator" content="MATLAB 8.0"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2013-02-19"><meta name="DC.source" content="prtDocCluster.m"><style type="text/css">
html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,sub,sup,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}:focus{outine:0}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}

html { min-height:100%; margin-bottom:1px; }
html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:10px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }
html body td { vertical-align:top; text-align:left; }

h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:1.5em; color:#d55000; line-height:100%; font-weight:normal; }
h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.2em; color:#000; font-weight:bold; line-height:140%; border-bottom:1px solid #d6d4d4; display:block; }
h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.1em; color:#000; font-weight:bold; line-height:140%; }

a { color:#005fce; text-decoration:none; }
a:hover { color:#005fce; text-decoration:underline; }
a:visited { color:#004aa0; text-decoration:none; }

p { padding:0px; margin:0px 0px 20px; }
img { padding:0px; margin:0px 0px 20px; border:none; }
p img, pre img, tt img, li img { margin-bottom:0px; } 

ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }
ul li { padding:0px; margin:0px 0px 7px 0px; }
ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }
ul li ol li { list-style:decimal; }
ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }
ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }
ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }
ol li ol li { list-style-type:lower-alpha; }
ol li ul { padding-top:7px; }
ol li ul li { list-style:square; }

.content { font-size:1.2em; line-height:140%; padding: 20px; }

pre, tt, code { font-size:12px; }
pre { margin:0px 0px 20px; }
pre.error { color:red; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }

.footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }
.footer p { margin:0px; }
.footer a { color:#878787; }
.footer a:hover { color:#878787; text-decoration:underline; }
.footer a:visited { color:#878787; }

table th { padding:7px 5px; text-align:left; vertical-align:middle; border: 1px solid #d6d4d4; font-weight:bold; }
table td { padding:7px 5px; text-align:left; vertical-align:top; border:1px solid #d6d4d4; }





  </style></head><body><div class="content"><h1>PRT Clustering Objects</h1><!--introduction--><p>Clustering is an operation very similar to classification. The main difference is that in clustering, the class labels are unknown. Instead of using known class labels, clustering sorts the data into discrete clusters, which are given integer labels. It is important to remember that when using clustering algorithms, the assignment of labels to clusters is completely arbitrary. For example, if you train a clustering algorithm with the same set of data twice, it is possible that the same sample could be labeled class 0 the first time, and class 1 the second time.</p><!--/introduction--><h2>Contents</h2><div><ul><li><a href="#1">Clustering object methods and properties.</a></li><li><a href="#2">Using clustering objects</a></li><li><a href="#5">Internal Deciders</a></li></ul></div><h2>Clustering object methods and properties.<a name="1"></a></h2><p>All prtCluster objects inherit the TRAIN, RUN, CROSSVALIDATE and KFOLDS functions from the prtAction object, for more information on these methods, refer to section on the  <a href="./prtDocEngine.html">prtEngine</a>.</p><h2>Using clustering objects<a name="2"></a></h2><p>You use classifiers in the same manner as any prtAction object. The following example shows how to create a k-means cluster object, and plot the decision regions.</p><pre class="codeinput">ds = prtDataGenUnimodal;       <span class="comment">% Load a dataset to use</span>
cluster = prtClusterKmeans     <span class="comment">% Create k-means clustering object</span>
cluster.nClusters = 2;         <span class="comment">% Set the number of clusters to 2</span>
cluster = cluster.train(ds);
plot(cluster)
</pre><pre class="codeoutput">cluster = 
  prtClusterKmeans

  Properties:
                         name: 'K-Means Clustering'
             nameAbbreviation: 'K-MeansCluster'
                    nClusters: 3
    kmeansHandleEmptyClusters: 'remove'
             distanceMetricFn: @prtDistanceEuclidean
               clusterCenters: []
              internalDecider: []
             includesDecision: 0
                 isSupervised: 0
         isCrossValidateValid: 1
               verboseStorage: 1
              showProgressBar: 1
                    isTrained: 0
               dataSetSummary: []
                      dataSet: []
                     userData: [1x1 struct]
</pre><img vspace="5" hspace="5" src="prtDocCluster_01.png" alt=""> <p>Note that in the above example, it was necessary to set the number of clusters to 2. This is an obvious choice because it is known that the data contains 2 classes. Clustering can also be done on M-ary data sets. For example:</p><pre class="codeinput">ds = prtDataGenMary;
cluster.nClusters = 3;
cluster = cluster.train(ds);
plot(cluster)
</pre><img vspace="5" hspace="5" src="prtDocCluster_02.png" alt=""> <p>In the above example, again the number of clusters in the orignal data was known to be 3, so the nClusters data member was set accordingly. Currently, all prtCluster algorithms require the number of clusters to be set before training.</p><h2>Internal Deciders<a name="5"></a></h2><p>Another important property of prtCluster objects is the internalDecider. Ordinarily, a prtCluster object outputs raw statistics based on the clustering algorithm, just like the prtClass objects do. However, you might just want the clustering object to also label the outputs. This can be done by setting the internalDecider property to be a prtDecision object. In this case, since our classifier is an M-ary classifier, we need to set the internal decider to be a prtDecisionMap object:</p><pre class="codeinput">cluster.internalDecider = prtDecisionMap;
result = cluster.kfolds(ds,2);   <span class="comment">%  Perform a simple 2-fold cross-validation</span>
</pre><p>All clustering objects in the Pattern Recognition Toolbox have the same API as discussed above. The only difference is the underlying clustering algorithms used to train and run. For a list of all the different clustering algorithms, and links to their individual help entries, <a href="prtDocFunctionList.html#2">A list of commonly used functions</a></p><p class="footer"><br><a href="http://www.mathworks.com/products/matlab/">Published with MATLAB&reg; R2012b</a><br></p></div><!--
##### SOURCE BEGIN #####
%% PRT Clustering Objects
% Clustering is an operation very similar to classification. The main
% difference is that in clustering, the class labels are unknown.
% Instead of using known class labels, clustering sorts the data into
% discrete clusters, which are given integer labels. It is important to
% remember that when using clustering algorithms, the assignment of labels
% to clusters is completely arbitrary. For example, if you train a
% clustering algorithm with the same set of data twice, it is possible that
% the same sample could be labeled class 0 the first time, and class 1 the
% second time.
%
%% Clustering object methods and properties.
% All prtCluster objects inherit the TRAIN, RUN, CROSSVALIDATE and KFOLDS
% functions from the prtAction object, for more information on these
% methods, refer to section on the  <./prtDocEngine.html prtEngine>.
%
%
%% Using clustering objects
% You use classifiers in the same manner as any prtAction object. The
% following example shows how to create a k-means cluster object, and plot
% the decision regions.

ds = prtDataGenUnimodal;       % Load a dataset to use
cluster = prtClusterKmeans     % Create k-means clustering object
cluster.nClusters = 2;         % Set the number of clusters to 2
cluster = cluster.train(ds);
plot(cluster)

%% 
% Note that in the above example, it was necessary to set the number of
% clusters to 2. This is an obvious choice because it is known that the
% data contains 2 classes. Clustering can also be done on M-ary data sets.
% For example:

ds = prtDataGenMary;
cluster.nClusters = 3;
cluster = cluster.train(ds);
plot(cluster)

%%
% In the above example, again the number of clusters in the orignal data
% was known to be 3, so the nClusters data member was set accordingly.
% Currently, all prtCluster algorithms require the number of clusters to be
% set before training.

%% Internal Deciders
% Another important property of prtCluster objects is the internalDecider.
% Ordinarily, a prtCluster object outputs raw statistics based on the
% clustering algorithm, just like the prtClass objects do. However, you
% might just want the clustering object to also label the outputs. This can
% be done by setting the internalDecider property to be a
% prtDecision object. In this case, since our classifier is an M-ary
% classifier, we need to set the internal decider to be a prtDecisionMap
% object:

cluster.internalDecider = prtDecisionMap;
result = cluster.kfolds(ds,2);   %  Perform a simple 2-fold cross-validation

%%
% All clustering objects in the Pattern Recognition Toolbox have the same
% API as discussed above. The only difference is the underlying clustering
% algorithms used to train and run. For a list of all the different
% clustering algorithms, and links to their individual help entries,
% <prtDocFunctionList.html#2 A list of commonly used functions>
##### SOURCE END #####
--></body></html>